dataset:
    name: 'planar'
    remove_h: null
    datadir: 'data/planar/'
    rand_perm: False
    feat:
        type:
            - deg
            - eig1
            - eig2
        scale: 10
        norm: True

general:
    # General settings
    name: 'graph-tf-model'      # Warning: 'debug' and 'test' are reserved name that have a special behavior

    process_visualization: False
    sample_visualization: False
    vis_number: 30

    wandb: 'disabled'             # online | offline | disabled
    gpus: [0, ]                     # Multi-gpu is not implemented on this branch

    resume: null            # If resume, path to ckpt file from outputs directory in main directory
    test_only: #'/media/ubuntu/6EAA3539AA34FEE1/LXY/GraphGeneration/BetaGraph_eta/outputs/planar/2024-05-10/16-35-10-graph-tf-model/checkpoints/graph-tf-model/epoch=14999-v1.ckpt'         # Use absolute path

    check_val_every_n_epochs: 1000
    sample_every_val: 1
    val_check_interval: null
    samples_to_generate: 120       # We advise to set it to 2 x batch_size maximum
    samples_to_save: 20
    chains_to_save: 1
    log_every_steps: 50
    number_chain_steps: 50        # Number of frames in each gif

    final_model_samples_to_generate: 120
    final_model_samples_to_save: 20
    final_model_chains_to_save: 20
    evaluate_all_checkpoints: False

train:
    # Training settings
    n_epochs: 100000
    batch_size: 64
    lr: 0.0002
    clip_grad: 1.0          # float, null to disable
    save_model: True
    num_workers: 0
    ema_decay: 0.999           # 'Amount of EMA decay, 0 means off. A reasonable value  is 0.999.'
    progress_bar: false
    weight_decay: 1e-12
    optimizer: adamw # adamw,nadamw,nadam => nadamw for large batches, see http://arxiv.org/abs/2102.06356 for the use of nesterov momentum with large batches
    seed: 0

model:
    # Model settings
    type: 'discrete'
    transition: 'marginal'                          # uniform or marginal
    model: 'graph_tf'
    diffusion_steps: 1000
    diffusion_noise_schedule: 'cosine'              # 'cosine', 'polynomial_2'
    n_layers: 7

    extra_features:          # 'all', 'cycles', 'eigenvalues' or null

    # Do not set hidden_mlp_E, dim_ffE too high, computing large tensors on the edges is costly
    # At the moment (03/08), y contains quite little information
    hidden_mlp_dims: {'X': 256, 'E': 64, 'y': 128}

    # The dimensions should satisfy dx % n_head == 0
    hidden_dims : {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 64, 'dim_ffy': 128}

    high_order: False
    # DruM Setting
    # hidden_mlp_dims: {'X': 128, 'E': 64, 'y': 128}
    # hidden_dims : {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 64, 'dim_ffy': 256}

    lambda_train: [5, 0]

    sigmoid_start: 10    # 9
    sigmoid_end: -13     # -9
    sigmoid_power: 1.  # 0.5
    scale_shift:
        node: [0.39, 0.6]    # originally 0.39
        edge: [0.39, 0.6]    # originally 0.6

    eta:
        node: [10000, 10000, 10000, 10000]
        edge: [30, 30, 30, 30]
    input_space: 'logit' # 'logit' or 'original'
    pre_condition: True

    noise_feat_type: 'eig' # 'deg', 'eig', 'all', None
    default_min_max: [-3.1, 3.1]  # None
    max_feat_num: [13, 1, 1]

    cibcentration_m: False
    concentration_strategy: 'deg' # 'deg', 'central', 'betweenness'

hydra:
  job:
    chdir: True
  run:
    dir: ../outputs/${dataset.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}-${general.name}
